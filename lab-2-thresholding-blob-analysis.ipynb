{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "b-eOa1Lh9lYo"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 2: Thresholding and blob analysis"
      ],
      "metadata": {
        "id": "2lvneRTAR2Tq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intro to Image Processing"
      ],
      "metadata": {
        "id": "N4l529B2U95S"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVQ72cRFIMtP"
      },
      "source": [
        "\n",
        "##Step 1: Load the Dependencies\n",
        "\n",
        "> This section loads some required libraries used in this notebook: **numpy**, **pandas**, **cv2**, **skimage**, **PIL**, **matplotlib**\n",
        "\n",
        "*   [Numpy](https://www.numpy.org/) is an array manipulation library, used for linear algebra, Fourier transform, and random number capabilities.\n",
        "*   [Pandas](https://pandas.pydata.org/) is a library for data manipulation and data analysis.\n",
        "*   [CV2](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_gui/py_image_display/py_image_display.html) is a library for computer vision tasks.\n",
        "*   [Skimage](https://scikit-image.org/) is a library which supports image processing applications on python.\n",
        "*   [Matplotlib](https://matplotlib.org/) is a library which generates figures and provides graphical user interface toolkit.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dy-iP-VTibt"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2 as cv \n",
        "import os\n",
        "from google.colab import files\n",
        "from google.colab.patches import cv2_imshow # for image display\n",
        "from skimage import io\n",
        "from PIL import Image \n",
        "import matplotlib.pyplot as plt\n",
        "import sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MYXdmP7fElG"
      },
      "source": [
        "##Step 2: Read Image from Urls\n",
        "\n",
        "> In this step we will read images from urls, and display them using openCV, please note the difference when reading images in RGB and BGR format. The default input color channels are in BGR (Blue, Green, Red) format for openCV."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tz7UAjxjfMuz"
      },
      "source": [
        "# Create a list of urls of the images\n",
        "urls = [\"https://placekitten.com/800/500\",\n",
        "        \"https://placekitten.com/600/400\"]\n",
        "\n",
        "# Read and display the images\n",
        "\n",
        "for url in urls:\n",
        "  # read image from url using skimage.io \n",
        "  image = io.imread(url) \n",
        "\n",
        "  # convert to RGB colorspace \n",
        "  image_2 = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
        "\n",
        "  # concantenate both images\n",
        "  final_frame = cv.hconcat((image, image_2))\n",
        "\n",
        "  # display images with OpenCV \n",
        "  cv2_imshow(final_frame)\n",
        "  print('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPYOeezmsWFj"
      },
      "source": [
        "#### ToDo #1: Read an image from a URL and display it\n",
        "\n",
        "Image source examples:\n",
        "\n",
        "[Place Kitten](https://placekitten.com/) - use the base Place Kitten URL followed by a width and height separated by backslashes ''/''. For example, use the URL `https://placekitten.com/500/300` to fetch a cat image with a width of 500px and height of 300px.\n",
        "\n",
        "[Google Image search](https://www.google.com/imghp?hl=en) - search for an image. Left-click one of the returned images, then right-click on the full image, and then select \"Copy Image Address\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQnoyw2SHUIc"
      },
      "source": [
        "## TODO: LOAD IMAGE\n",
        "## url = \n",
        "## myImg = io.imread(url)\n",
        "## myImg_rgb = cv.cvtColor(myImg, cv.COLOR_BGR2RGB)\n",
        "## cv2_imshow(myImg_rgb)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q2tzCPzNDHA"
      },
      "source": [
        "##Step 3: Image Data and Histograms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wedge-tailed eagle photo\n",
        "eagle_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/0/03/Wedge-tailed_Eagle_It_is_Not_Even_Playing_the_Game%21_%2850096251297%29.jpg/513px-Wedge-tailed_Eagle_It_is_Not_Even_Playing_the_Game%21_%2850096251297%29.jpg\""
      ],
      "metadata": {
        "id": "6b8sQpupbenk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load image of eagle\n",
        "image = io.imread(eagle_url)\n",
        "\n",
        "# convert to RGB\n",
        "image_rgb = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
        "\n",
        "# concantenate both images\n",
        "final_frame = cv.hconcat((image, image_rgb))\n",
        "\n",
        "# Display the image\n",
        "cv2_imshow(final_frame)"
      ],
      "metadata": {
        "id": "xKKxwXDRPs6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfJA1BUlOhCu"
      },
      "source": [
        "# Check the image matrix data type \n",
        "print('dtype:', image_rgb.dtype)\n",
        "\n",
        "# Check the image dimensions \n",
        "print('dimensions [w, h]:', [image_rgb.shape[1], image_rgb.shape[0]])\n",
        "\n",
        "# Check the number of channels of the image\n",
        "print('image channels:', image_rgb.shape[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: **uint8** means that we have a matrix of 8-bit unsigned integers "
      ],
      "metadata": {
        "id": "h-xZEXd-u6UO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlHHA4CDogVd"
      },
      "source": [
        "### Generate a histogram of the color image\n",
        "Sometimes you want to enhance the contrast in your image or expand the contrast in a particular region. A good tool to find interesting regions is the histogram, which shows a frequency distribution of the color values in an image. To create a histogram of our image data, we use the matplotlib.pyplot `hist()` function.\n",
        "\n",
        "More info: [Histogram](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.hist.html#matplotlib.pyplot.hist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiI_Oyi7xOD9"
      },
      "source": [
        "Display the histogram of all the pixels in the color image with `plt.hist()`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ugbLMdXPOdE"
      },
      "source": [
        "plt.hist(image.ravel(), bins = 256, range = [0,256])\n",
        "plt.xlabel('value') \n",
        "plt.ylabel('count')\n",
        "plt.title('eagle image histogram')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:** \n",
        "What do you think the four peaks in the eagle histogram correspond to? "
      ],
      "metadata": {
        "id": "hMqmdCmskbua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Response:**"
      ],
      "metadata": {
        "id": "2KPyxOcDk0rL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####ToDo #2: Plot a histogram of your image `myImg_rgb` \n",
        "\n",
        "Be sure to add axis labels and a title \n"
      ],
      "metadata": {
        "id": "jFeZGGYCQsxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## plt.hist(myImg_rgb.ravel(),bins = 256, range = [0,256]) \n",
        "##\n",
        "##\n",
        "##\n",
        "##"
      ],
      "metadata": {
        "id": "hvJZ-R4gQog0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2V0pqbfAxTIn"
      },
      "source": [
        "Now we'll display the histogram of each color channel (B, G, R)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyNrxffGw1mm"
      },
      "source": [
        "# Set colors for plotting each channel\n",
        "color = ('b','g','r')\n",
        "for i,col in enumerate(color):\n",
        "    # calculate histogram\n",
        "    image_hist = cv.calcHist([image], [i], None, [256], [0,256])\n",
        "    plt.plot(image_hist, color = col)\n",
        "    plt.xlim([0,256])\n",
        "plt.xlabel('color value')\n",
        "plt.ylabel('count')\n",
        "plt.title('Histogram of each color channel')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that the blue channel has a large peak at a value of around 90. This corresponds to the pixels that comprise the sky in the eagle image. "
      ],
      "metadata": {
        "id": "XTtTQPyprT1M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####ToDo #3 Plot a histogram of each color for your image"
      ],
      "metadata": {
        "id": "rp46KTAAr5PR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Code in this cell"
      ],
      "metadata": {
        "id": "ex3mptnksLvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 4: Grayscale "
      ],
      "metadata": {
        "id": "pMkIX1gkoWBL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLGWfkdtFM-v"
      },
      "source": [
        "# Convert color image to grayscale\n",
        "gray_image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
        "cv2_imshow(gray_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZEybZ7toJD9"
      },
      "source": [
        "# Plot the histogram of the gray image\n",
        "plt.hist(gray_image.ravel(),bins = 256, range = [0, 256])\n",
        "plt.xlabel('value')\n",
        "plt.ylabel('count')\n",
        "plt.title('Grayscale histogram')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** The frequency of the image histogram has decreased by about 1/3 of the histogram of color image. \n",
        "\n",
        "We can see why by looking at the dimensions of the original color image and of the grayscale image. \n",
        "\n",
        "To do this we'll view the shape of the image matrix. The first two dimensions `(M, N)` correspond to the number of rows and columns of the image, respectively.  "
      ],
      "metadata": {
        "id": "SxDB0GvDoosb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the color image dimensions\n",
        "print('color image dimensions:', image.shape)\n",
        "\n",
        "# Check the grayscale image dimensions\n",
        "print('grayscale image dimensions:', gray_image.shape)"
      ],
      "metadata": {
        "id": "RFfaNlgwpK9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJf42iHqpTND"
      },
      "source": [
        "#### ToDo #4: Display the grayscale of your image and generate its histogram\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWiUtmjRHmQ9"
      },
      "source": [
        "## grayscale"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## grayscale histogram"
      ],
      "metadata": {
        "id": "1VnxXW9rRXop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Thresholding \n",
        "Thresholding converts images to binary images, which we can then use to localize objects and obtain information about their size, shape, and position."
      ],
      "metadata": {
        "id": "Dw4hsE5SVEys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Helper function to plot multiple images\n",
        "def plot_img(images, titles):\n",
        "  fig, axs = plt.subplots(nrows = 1, ncols = len(images), figsize = (15, 15))\n",
        "  for i, p in enumerate(images):\n",
        "    axs[i].imshow(p, 'gray')\n",
        "    axs[i].set_title(titles[i])\n",
        "    #axs[i].axis('off')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "caYVnLAlbUyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Side Note:** Here we are using a different method to display images. We are calling the `plt.imshow()` method, which reads an `(M, N, 3)` image as RGB values rather than BGR like `cv2_imshow()`."
      ],
      "metadata": {
        "id": "y7kKamKsTu1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download a useful image for the following sections of the tutorial\n",
        "\n",
        "!wget https://raw.githubusercontent.com/adsoto/Shark-Analysis/main/zf-shoal-00004.jpg\n",
        " "
      ],
      "metadata": {
        "id": "Sm59m0ocmPb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To load an image using OpenCV, we can use the `imread()` function"
      ],
      "metadata": {
        "id": "JPU9WyCHMuC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the fish image \n",
        "im1 = cv.imread('zf-shoal-00004.jpg') "
      ],
      "metadata": {
        "id": "1H_KitcQnado"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the image\n",
        "cv2_imshow(im1)"
      ],
      "metadata": {
        "id": "zGOBwgPanlub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If this was a python script or Jupyter notebook running locally on your machine, you could read an image with a function call similar to the following:\n",
        "\n",
        "`im = cv.imread('/image/path/image_name.jpg')`"
      ],
      "metadata": {
        "id": "dZEGadKrNZP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Image dimensions\n",
        "print('Original Dimensions : ', im1.shape)"
      ],
      "metadata": {
        "id": "GlFDVyYHorHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This image is large, let's resize for efficiency and easier viewing"
      ],
      "metadata": {
        "id": "CcLjR6vpog9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# scale factor (0 to 1, where 1 returns the original size)\n",
        "scale_factor = 0.5\n",
        "\n",
        "# generate dimensions for resized image\n",
        "width = int(im1.shape[1] * scale_factor)\n",
        "height = int(im1.shape[0] * scale_factor)\n",
        "dim = (width, height)\n",
        "  \n",
        "# resize image\n",
        "im2 = cv.resize(im1, dim, interpolation = cv.INTER_AREA)\n",
        " \n",
        "print('Resized Dimensions : ', im2.shape)"
      ],
      "metadata": {
        "id": "5MVnqQRXogie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the resized image\n",
        "cv2_imshow(im2)"
      ],
      "metadata": {
        "id": "65ji0lVVpuva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple Thresholding\n",
        "If a pixel value is greater than the threshold value, it is assigned one value (may be white), else it is assigned another value (may be black). The function used is \n",
        "```\n",
        "cv.threshold(img, thresh_value, maxVal, style)\n",
        "```\n",
        "*   First argument is the source image (typically a grayscale image).\n",
        "*   Second argument is the threshold value which is used to classify the pixel values.\n",
        "*   Third argument is the maxVal which represents the value to be given if pixel value is more than (sometimes less than) the threshold value. \n",
        "*   Third argument is the style of thresholding. OpenCV provides different styles of thresholding. We'll only try out the first two, but you can try the others yourself by providing the desired arugment. \n",
        "\n",
        "  1.  *cv.THRESH_BINARY*\n",
        "  2.  *cv.THRESH_BINARY_INV*\n",
        "  3.  *cv.THRESH_TRUNC*\n",
        "  4.  *cv.THRESH_TOZERO*\n",
        "  5.  *cv.THRESH_TOZERO_INV*\n",
        "\n",
        "![alt text](https://miro.medium.com/max/730/1*swjBYQOnuNfv1rHM3p39PQ.png) \n",
        "\n",
        "**I(x, y)** is the intensity at the point, or the pixel value at (x, y).\n",
        "\n",
        "\n",
        "Two outputs are obtained from the `cv.threshold()` function. The first one is a **retval**, the threshold used (or caluclated) by the thresholding method. Second output is the thresholded image."
      ],
      "metadata": {
        "id": "8a7lGlpeaZlJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Binary"
      ],
      "metadata": {
        "id": "NLPWLbc4i5st"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Binary Thresholding\n",
        "\n",
        "# set the desired threshold value \n",
        "thresh_val = 70\n",
        "\n",
        "# Convert to grayscale\n",
        "im2_gray = cv.cvtColor(im2, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "# apply thresholding\n",
        "ret, im2_binary = cv.threshold(im2_gray, thresh_val, 255, cv.THRESH_BINARY)\n",
        "\n",
        "# Plot the images\n",
        "images = [im2, im2_gray, im2_binary]\n",
        "titles = ['Original image', 'Grayscale', 'THRESH_BINARY']\n",
        "plot_img(images, titles)"
      ],
      "metadata": {
        "id": "uCv0o0ZacItC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ToDo #5: Modify the threshold value to describe its effect. \n",
        "Do this multiple times for **thresh_val** between 0 and 255. "
      ],
      "metadata": {
        "id": "1lC-3mcar6d8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set the threshold value \n",
        "thresh_val = 30\n",
        "\n",
        "# apply thresholding\n",
        "ret, binary = cv.threshold(im2_gray, thresh_val, 255, cv.THRESH_BINARY)\n",
        "\n",
        "# Plot the images\n",
        "images = [im2_gray, binary]\n",
        "titles = ['Graysclae Image', 'THRESH_BINARY']\n",
        "plot_img(images, titles)"
      ],
      "metadata": {
        "id": "ZmD2A5yTrqkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Describe effect of `thresh_val` here:"
      ],
      "metadata": {
        "id": "2c5AHxpSfAkK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Binary Inverse"
      ],
      "metadata": {
        "id": "_Rw3ucHvi2zh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Binary Inverse Thresholding\n",
        "thresh_val = 80\n",
        "ret, im_binary_inv = cv.threshold(im2_gray, thresh_val, 255, cv.THRESH_BINARY_INV)\n",
        "\n",
        "# Plot the images\n",
        "images = [im2_gray, im_binary_inv]\n",
        "titles = ['Graysclae Image', 'THRESH_BINARY_INV']\n",
        "plot_img(images, titles)"
      ],
      "metadata": {
        "id": "bPKlEbVxi1U4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** This method could be very useful for blob analysis (next Section) on this image because the objects of interest are considered foreground (white) pixels. "
      ],
      "metadata": {
        "id": "qewZpqX-d2vQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Otsu’s Binarization\n",
        "Otsu’s Binarization is used to perform automatic image thresholding. It automatically calculates a threshold value from the image histogram for a bimodal image. A bimodal image is an image with two distinct peaks (or humps) in its histogram.\n",
        "\n",
        "We use the usual threshold function `cv.threshold()`, but pass an extra flag, *cv.THRESH_OTSU*. For threshold value, simply pass zero. Then the algorithm finds the optimal threshold value which is returned as `retVal`. If Otsu thresholding is not used, retVal is same as the threshold value you input."
      ],
      "metadata": {
        "id": "Wk4iGNeaa3b_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# global thresholding\n",
        "ret_binary, img_binary = cv.threshold(im2_gray, 80, 255, cv.THRESH_BINARY)\n",
        "\n",
        "# Otsu's thresholding\n",
        "ret_otsu, img_otsu_binary = cv.threshold(im2_gray,0,255, cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
        "\n",
        "# Plot the images\n",
        "images = [im2, img_binary, img_otsu_binary]\n",
        "titles = ['Original image', 'THRESH_BINARY; retVal:' + str(ret_binary), 'THRESH_OTSU; retVal:' + str(ret_otsu)]\n",
        "plot_img(images, titles)"
      ],
      "metadata": {
        "id": "k6jpt-s7a-sb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, the automatic thresholding function doesn't guarantee better results. It depends a lot on the input image and what features you're interested in. "
      ],
      "metadata": {
        "id": "L-agQWL7i7nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Adaptive thresholding\n",
        "In Simple thresholding, we used a global value as threshold value. But it may not be good in all the conditions where image has different lighting conditions in different areas. In that case, we go for adaptive thresholding. In this, the algorithm calculate the threshold for a small regions of the image. So we get different thresholds for different regions of the same image and it gives us better results for images with varying illumination.\n",
        "```\n",
        "cv.adaptiveThreshold(img, maxValue, adaptiveMethod, thresholdType, blockSize, C)\n",
        "```\n",
        "It has three ‘special’ input params and only one output argument.\n",
        "\n",
        "*   **Adaptive Method** :\n",
        "  1. cv.ADAPTIVE_THRESH_MEAN_C : threshold value is the mean of neighbourhood area.\n",
        "  2. cv.ADAPTIVE_THRESH_GAUSSIAN_C : threshold value is the weighted sum of neighbourhood values where weights are a gaussian window.\n",
        "*   **Block Size** - It decides the size of neighbourhood area.\n",
        "*   **C** - It is just a constant which is subtracted from the mean or weighted mean calculated."
      ],
      "metadata": {
        "id": "y9P3vfdKbyah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adaptive Threshold Mean C\n",
        "im_thresh_mean_c = cv.adaptiveThreshold(im2_gray, 255, cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY, 11, 2)\n",
        "\n",
        "# Plot the original, simple threshold, and adaptive threshold images\n",
        "images = [im2_gray, im2_binary, im_thresh_mean_c]\n",
        "titles = ['Graysclae Image', 'THRESH_BINARY', 'ADAPTIVE_THRESH_MEAN_C']\n",
        "plot_img(images, titles)"
      ],
      "metadata": {
        "id": "tDdqH_GWffCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adaptive Threshold Mean C\n",
        "im_thresh_gauss_c = cv.adaptiveThreshold(im2_gray, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 11, 2)\n",
        "\n",
        "# Plot the original, simple threshold, and adaptive threshold images\n",
        "images = [im2_gray, im_thresh_mean_c, im_thresh_gauss_c]\n",
        "titles = ['Graysclae Image', 'ADAPTIVE_THRESH_MEAN_C', 'ADAPTIVE_THRESH_GAUSSIAN_C']\n",
        "plot_img(images, titles)"
      ],
      "metadata": {
        "id": "4BO7PVb0vpDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ToDo #6\n",
        "\n",
        "Based on what you observe in the images above, describe the effect that the Gaussian_C method has on the thresholding compared to the Mean_C method. "
      ],
      "metadata": {
        "id": "M5Tk_gkCwgFR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Describe difference here:"
      ],
      "metadata": {
        "id": "zVKQxWN5w2OL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Thresholding a color image\n",
        "> I mentioned in the Simple Thresholding section that we typically apply thresholding to grayscale images. So is it possible to threshold a color image? \n",
        "\n",
        "Let's try it!\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Uqbgw2aoXZkx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# apply thresholding directly to color image of eagle\n",
        "ret, eagle_binary = cv.threshold(image_rgb, thresh_val, 255, cv.THRESH_BINARY)\n",
        "\n",
        "# Plot the images\n",
        "images_1 = [image, eagle_binary]\n",
        "titles_1 = ['Original image', 'Threshold (color)']\n",
        "plot_img(images_1, titles_1)"
      ],
      "metadata": {
        "id": "yJ6uA002QNgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# apply thresholding to graysale image of eagle\n",
        "ret, eagle_gray_binary = cv.threshold(gray_image, 100, 255, cv.THRESH_BINARY)\n",
        "\n",
        "images_2 = [gray_image, eagle_gray_binary]\n",
        "titles_2 = ['Grayscale', 'Threshold (gray)']\n",
        "plot_img(images_2, titles_2)"
      ],
      "metadata": {
        "id": "eQdcuTjGldF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thresholding on color channels is possible and may be a useful way of isolating image features within a particualr color range. "
      ],
      "metadata": {
        "id": "1hG2rFjVbFrP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Blob analysis\n",
        "This section makes use of our binary images to find connected components, or **blobs** in the image - usually the white pixels in a binary image. "
      ],
      "metadata": {
        "id": "qOoW0frmFcSo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Contours\n",
        "\n",
        "A contour is the set of points joining all the continuous points (along the boundary) that have same color or intensity. This is another name for **blob**\n",
        "\n",
        "There are three arguments in the `cv.findContours(img, mode, method)` function. The first one is the source image, second is contour retrieval mode, third is contour approximation method. \n",
        "\n",
        "It outputs the contours and hierarchy. *contours* is a list of all the contours in the image. Each individual contour is a Numpy array of (x,y) coordinates for the boundary points of the blob."
      ],
      "metadata": {
        "id": "KvsHP3AsHBwX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we'll apply `cv.findContours()` to `im2_binary` from the previous section."
      ],
      "metadata": {
        "id": "62rCWFO3Iyme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# find the image contours\n",
        "contours, hierarchy = cv.findContours(im2_binary, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)"
      ],
      "metadata": {
        "id": "4gRYlq5vhShb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of Contours found = \" + str(len(contours)))"
      ],
      "metadata": {
        "id": "g7-n9McgYOya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To visualize the contours we'll use `cv.drawContours()`, \n",
        "\n",
        "Its first argument is the source image, second argument is the contours which should be passed as a Python list, third argument is the index of contours (useful when drawing an individual contour -- to draw all contours, pass -1) and remaining arguments are color and thickness.\n",
        "\n",
        "We'll create a copy of the `im2` image so that we can draw the contours and preserve the original."
      ],
      "metadata": {
        "id": "OMjGQDYOpKzL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy the image to preserve original\n",
        "im2_copy = im2.copy()\n",
        "\n",
        "# overlay the contours on the original image \n",
        "im2_overlay = cv.drawContours(im2_copy, contours, -1, (0,255,0), 1)\n",
        "\n",
        "# Plot the image with overlayed contours \n",
        "cv2_imshow(im2_overlay)"
      ],
      "metadata": {
        "id": "609bawpqbVVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sort contours by area"
      ],
      "metadata": {
        "id": "-aNcXEYNNkBr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's draw only the first 10 contours to visualize where they are."
      ],
      "metadata": {
        "id": "mSaxgih2ukb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy the image to preserve original\n",
        "im2_copy = im2.copy()\n",
        "\n",
        "# Draw the first 10 contours from the unsorted list\n",
        "im2_unsorted = cv.drawContours(im2_copy, contours[0:9], -1, (0,255,0), 2)\n",
        "\n",
        "# Plot the image with overlayed contours \n",
        "cv2_imshow(im2_unsorted)"
      ],
      "metadata": {
        "id": "S2P9gzccqNNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do you see the green contours?\n",
        "> They are very small and aren't features we're interested in. What we're after are the contours that outline the fish. So we'll sort the contours list, hopefully they are the largest contours in the image. "
      ],
      "metadata": {
        "id": "ufB3wnzdtaIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# largest to smallest sorted list\n",
        "sorted_contours = sorted(contours, key = cv.contourArea, reverse = True)"
      ],
      "metadata": {
        "id": "WyP2BNwGNm2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy the image to preserve original\n",
        "im2_copy = im2.copy()\n",
        "\n",
        "# Draw the first 10 contours from the unsorted list\n",
        "im2_sorted = cv.drawContours(im2_copy, sorted_contours[0:9], -1, (0,255,0), 2)\n",
        "\n",
        "# Plot the image with overlayed contours \n",
        "cv2_imshow(im2_sorted)"
      ],
      "metadata": {
        "id": "FrRPVdBjudgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So the fish are not the largest contours, but they are among the largest. Now we can use information about their area to be more selective as we extract properties of the fish blobs. "
      ],
      "metadata": {
        "id": "TzEc2UOfv31V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract blob properties"
      ],
      "metadata": {
        "id": "No028C6ILHUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to find some useful properties for sorting and localizing objects\n",
        "\n",
        "def blob_properties(contours):\n",
        "\n",
        "  # initialize list to keep track of blob properties\n",
        "  cont_props = []\n",
        "  i = 0\n",
        "\n",
        "  # loop through each contour to find their properties\n",
        "  for cnt in contours:\n",
        "\n",
        "    # compute contour moments\n",
        "    M = cv.moments(cnt)\n",
        "\n",
        "    # compute centroid of contour\n",
        "    cx = int(M['m10']/M['m00'])\n",
        "    cy = int(M['m01']/M['m00'])\n",
        "\n",
        "    area = cv.contourArea(cnt)\n",
        "\n",
        "    # Add parameters to list\n",
        "    add = [i, (cx, cy), area]\n",
        "    cont_props.append(add)\n",
        "    i += 1\n",
        "\n",
        "  return cont_props"
      ],
      "metadata": {
        "id": "Q7ilb99jLLT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's call `blob_properties()` to get the centroid position and area of the first 10 contours of our sorted list. "
      ],
      "metadata": {
        "id": "6bz9hfLkwvCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cont_props = blob_properties(sorted_contours[0:10])"
      ],
      "metadata": {
        "id": "z6y28nNSUYKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cont_props"
      ],
      "metadata": {
        "id": "MRCYdqAVw9g1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 2: Homework\n",
        "Create a new Google Colab notebook with the title **lab_2_hw_your_initials** for this assignment. \n",
        "\n",
        "Using one of the images from your ball throwing sequence (choose one where the ball is clearly visible), do the following:\n",
        "\n",
        "> 1. Plot the full image histogram\n",
        "1. Plot the histogram of each color channel\n",
        "1. Convert the image to grayscale and display its histogram\n",
        "1. Apply a thresholding technique of your choice such that the we clearly see the ball blob.\n",
        "1. Plot the original, grayscale, and binary images together (side-by-side)\n",
        "1. Compute the image contours and visualize them \n",
        "1. Extract and print the centroid position of the ball blob and its area\n",
        "\n",
        "You will submit a pdf of the complete notebook (try: File-->Print-->Save as PDF) as well as the notebook itself (File-->Download-->Download .ipynb).\n",
        "\n",
        "**Note:** Every student will submit their own pdf (on gradescope) and notebook (on Google Drive). "
      ],
      "metadata": {
        "id": "kF4BNKnv_udn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## File upload code to import an image from your hard drive. \n",
        "Here's a code snippet that will be useful for the homework. \n",
        "\n",
        "Run the cell and then clink `Choose Files`"
      ],
      "metadata": {
        "id": "Dv-1ZRnSDecj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import one of your ball throwing images \n",
        "\n",
        "uploaded = files.upload()\n",
        "for filepath in uploaded.keys():\n",
        "  print(f'User uploaded file \"{filepath}\"')\n",
        "\n",
        "img_filepath = os.path.abspath(filepath)\n",
        "img_ball = cv.imread(img_filepath) "
      ],
      "metadata": {
        "id": "EBUNPSSMTYj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sources\n",
        "This notebook was adapted from Prof Soto's notes and the following sources:\n",
        "\n",
        "[source 1](https://docs.opencv.org/4.x/index.html)\n",
        "\n",
        "[source 2](https://github.com/xn2333/OpenCV/blob/master/Seminar_Image_Processing_in_Python.ipynb)\n",
        "\n",
        "[source 3](https://code.adonline.id.au/blob-analysis-with-opencv-in-python/)\n",
        "\n",
        "[source 4](https://learnopencv.com/blob-detection-using-opencv-python-c/)"
      ],
      "metadata": {
        "id": "FAtinbiOFVtd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extras (not needed)"
      ],
      "metadata": {
        "id": "b-eOa1Lh9lYo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[source](https://learnopencv.com/blob-detection-using-opencv-python-c/)\n",
        "\n",
        "[source](https://rubikscode.net/2022/06/13/thresholding-edge-contour-and-line-detection-with-opencv/)"
      ],
      "metadata": {
        "id": "sRmF3rNXcndy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to find some useful properties for sorting and localizing objects\n",
        "\n",
        "# def blob_properties_full(contours):\n",
        "\n",
        "#   # initialize list to keep track of blob properties\n",
        "#   cont_props= []\n",
        "#   i = 0\n",
        "\n",
        "#   # loop through each contour to find their properties\n",
        "#   for cnt in contours:\n",
        "\n",
        "#     # compute contour moments\n",
        "#     M = cv.moments(cnt)\n",
        "\n",
        "#     # compute centroid of contour\n",
        "#     cx = int(M['m10']/M['m00'])\n",
        "#     cy = int(M['m01']/M['m00'])\n",
        "\n",
        "#     area = cv.contourArea(cnt)\n",
        "#     perimeter = cv.arcLength(cnt,True)\n",
        "\n",
        "#     # bounding rectangle\n",
        "#     x1,y1,w,h = cv.boundingRect(cnt)\n",
        "#     x2 = x1+w\n",
        "#     y2 = y1+h\n",
        "#     aspect_ratio = float(w)/h\n",
        "\n",
        "#     # convex hull and hull area\n",
        "#     hull = cv.convexHull(cnt)\n",
        "#     hull_area = cv.contourArea(hull)\n",
        "\n",
        "#     rect = cv.minAreaRect(cnt)\n",
        "#     ellipse = cv.fitEllipse(cnt)\n",
        "\n",
        "#     # Add parameters to list\n",
        "#     add = [i, cx, cy, area, round(perimeter, 1), round(aspect_ratio, 3), w, h, round(hull_area, 1), x1, y1, x2, y2, rect, ellipse]\n",
        "#     cont_props.append(add)\n",
        "#     i += 1\n",
        "\n",
        "#   return cont_props"
      ],
      "metadata": {
        "id": "kU89NPYN3guc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}